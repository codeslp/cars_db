{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting, cleaning, standardizing, normalizing, and loading:\n",
    "First creating and initiating our venv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -m venv venv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install sqlalchemy\n",
    "# pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ingest to a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/bfaris96/Desktop/turing-proj/cars_db/FINAL_SPINNY_900.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for any nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stripping extra whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(lambda x: ' '.join(x.split()) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcing lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.applymap(lambda s: s.lower() if type(s) == str else s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating duplicate entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Engine_Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all non-numeric characters from mileage and price columns. \n",
    "\n",
    "- Note about my process (which I am willing to change): I have used regex when I need to parse or alter part of a string within a cell. If I can just use the whole cell contents, I use if/elif statements. I do this because I want to avoid regex, because I find it annoying. Regex is also slow, but that doesn't really matter at this scale (small data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mileage_Run'] = df['Mileage_Run'].str.replace(r'\\D', '', regex=True)\n",
    "df['Price'] = df['Price'].str.replace(r'\\D', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing year range from name field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_date_name(row):\n",
    "    # Split the car name field into individual words/phrases\n",
    "    name_list = list(row[\"Car_Name\"].split())\n",
    "\n",
    "    # Create regex to match [2000-2018] type strings in name\n",
    "    year_pattern = re.compile(r\"\\[(\\d{4})-(\\d{4})\\]\")\n",
    "    year_match = re.search(year_pattern, row[\"Car_Name\"])\n",
    "\n",
    "    # Remove from name list if match found\n",
    "    if year_match is not None and year_match.group(0) in name_list:\n",
    "        name_list.remove(year_match.group(0))\n",
    "\n",
    "    return \" \".join(name_list)\n",
    "    \n",
    "df[\"Car_Name\"] = df.apply(remove_date_name, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing redundant words from engine_type field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_engine(df):\n",
    "    engine_string = df[\"Engine_Type\"]\n",
    "    # Remove the pattern of number followed by the word \"speed\"\n",
    "    engine_string = re.sub(r'\\b\\d+\\s*speed\\b', '', engine_string)\n",
    "\n",
    "    # Now we split the string into a list of words\n",
    "    engine_list = engine_string.split()\n",
    "\n",
    "    # Define the list of unwanted words\n",
    "    unwanted_words = [\"petrol\", \"(petrol)\", \"diesel\", \"(diesel)\", \"cng\", \"(cng)\", \"lpg\", \"electric\", \"petrol+cng\", \"petrol+electric\", \"engine\", \"automatic\", \"manual\", \"transmission\"]\n",
    "\n",
    "    # Create a new list with only the words that are not in unwanted_words\n",
    "    engine_list = [word for word in engine_list if word not in unwanted_words]\n",
    "\n",
    "    # Join the words back together into a string\n",
    "    new_engine = \" \".join(engine_list)\n",
    "    return new_engine\n",
    "\n",
    "df[\"Engine_Type\"] = df.apply(clean_engine, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting engine_litres columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['engine_litres'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving engine litres data from either name or engine_type fields into new engine_litres field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_liters(row):\n",
    "\n",
    "    # Create a regular expression to match engine sizes in litres (e.g., 2.5l)\n",
    "    liter_pattern = re.compile(r\"\\b\\d+\\.\\d+[lL]\\b\")\n",
    "    \n",
    "    # Create a regular expression to match numeric values (e.g., 2.5)\n",
    "    no_l_liter_pattern = re.compile(r\"\\b\\d+\\.\\d+\\b\")\n",
    "\n",
    "    fields = [row[\"Car_Name\"], row[\"Engine_Type\"]]\n",
    "\n",
    "    for pattern in [liter_pattern, no_l_liter_pattern]:\n",
    "        for field in fields:\n",
    "            match = re.search(pattern, field)\n",
    "            if match is not None:\n",
    "                if pattern == liter_pattern:\n",
    "                    return match.group(0)[:-1]\n",
    "                elif pattern == no_l_liter_pattern:\n",
    "                    return match.group(0)\n",
    "    return None\n",
    "\n",
    "df['engine_litres'] = df.apply(move_liters, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More patterns to be removed left over from litre information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression patterns to be removed\n",
    "patterns = [\n",
    "    r\"\\b\\d+\\.\\d+\\s[lL]\\b\", # Matches '1.2 l' or '2.2 l' with a space before the 'l'\n",
    "    r\"\\b\\d+\\.\\d+[lL]?\\b\", # Matches '1.6l' or '1.9l' with no space before the 'l' and 'l' is optional\n",
    "    r\"( litre)|(-litre)\", # Matches ' litre' or '-litre'\n",
    "    r\"gasoline\" # Matches 'gasoline'\n",
    "]\n",
    "\n",
    "# Apply each pattern to each column\n",
    "for column in [\"Car_Name\", \"Engine_Type\"]:\n",
    "    for pattern in patterns:\n",
    "        df[column] = df[column].apply(lambda x: re.sub(pattern, \"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove redundant words (that appear in other fields) from car name field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(row):\n",
    "\n",
    "    # Initialize a list to store the cleaned name\n",
    "    new_name_list = list()\n",
    "\n",
    "    # Split the name, engine type, car make and model into individual words\n",
    "    name_list = row[\"Car_Name\"].split()\n",
    "    make_words = row[\"Make\"].split()\n",
    "    model_words = row[\"Model\"].split()\n",
    "    engine_type_words = row[\"Engine_Type\"].split()\n",
    "\n",
    "    # For each word in the car name, if it is not in the engine type, make, model or other row values, add it to the new name\n",
    "    for word in name_list:\n",
    "        if word not in engine_type_words and word not in model_words and word not in make_words and word not in row[\"Fuel_Type\"]:\n",
    "            new_name_list.append(word)\n",
    "\n",
    "    return \" \".join(new_name_list)\n",
    "\n",
    "df[\"Car_Name\"] = df.apply(clean_name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove drive train info from engine type, put in new drive train column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"drive_train\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_drive_train(row):\n",
    "    # Create a regular expression to match drive train types\n",
    "    drive_train_pattern = re.compile(r\"\\b\\w+\\s+wheel\\s+drive\\b\")\n",
    "\n",
    "    match = re.search(drive_train_pattern, row[\"Engine_Type\"])\n",
    "    if match is not None:\n",
    "        return match.group(0)\n",
    "\n",
    "df[\"drive_train\"] = df.apply(move_drive_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove drive train from engine type: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_train_pattern = re.compile(r\"\\b\\w+\\s+wheel\\s+drive\\b\")\n",
    "df[\"Engine_Type\"] = df[\"Engine_Type\"].apply(lambda x: re.sub(drive_train_pattern, \"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further understand how to standardize and constrain columns, I'll inspect all the unique values for relevant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll convert owner ordinals to an int:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owner_to_int(df):\n",
    "    if df['No_of_Owners'] == '1st':\n",
    "        return 1\n",
    "    elif df['No_of_Owners'] == '2nd':\n",
    "        return 2\n",
    "    elif df['No_of_Owners'] == '3rd':\n",
    "        return 3\n",
    "    elif df['No_of_Owners'] == '4th':\n",
    "        return 4\n",
    "    elif df['No_of_Owners'] == '5th':\n",
    "        return 5\n",
    "\n",
    "\n",
    "df['No_of_Owners'] = df.apply(owner_to_int, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove \"+\" from these fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_fuel_type(df):\n",
    "    if df['Fuel_Type'] == 'petrol+cng':\n",
    "        return 'petrol_cng'\n",
    "    elif df['Fuel_Type'] == 'petrol+electric':\n",
    "        return 'petrol_electric'\n",
    "\n",
    "df['Fuel_Type'] = df.apply(shorten_fuel_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will shorten the transmission gears field to 1 character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_transmission_gears(df):\n",
    "    if df['Transmission'] == '7-speed':\n",
    "        return 7\n",
    "    elif df['Transmission'] == '6-speed':\n",
    "        return 6\n",
    "    elif df['Transmission'] == '5-speed':\n",
    "        return 5\n",
    "    elif df['Transmission'] == '4-speed':\n",
    "        return 4\n",
    "\n",
    "df['Transmission'] = df.apply(shorten_transmission_gears, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shorten the drive train field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_drive_train(df):\n",
    "    if df['drive_train'] == 'front wheel drive':\n",
    "        return 'fwd'\n",
    "    elif df['drive_train'] == 'rear wheel drive':\n",
    "        return 'rwd'\n",
    "    elif df['drive_train'] == 'all wheel drive':\n",
    "        return 'awd'\n",
    "    elif df['drive_train'] == 'four wheel drive':\n",
    "        return '4wd'\n",
    "    \n",
    "df['drive_train'] = df.apply(shorten_drive_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip whitespace and commas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Engine_Type\"] = df[\"Engine_Type\"].str.rstrip()\n",
    "df[\"Engine_Type\"] = df[\"Engine_Type\"].str.lstrip()\n",
    "# Strip commas\n",
    "df[\"Engine_Type\"] = df[\"Engine_Type\"].str.replace(\",\", \"\")\n",
    "df[\"Engine_Type\"] = df[\"Engine_Type\"].str.replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the max number of rows to None (no limit)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "for column in df.columns:\n",
    "    print(f\"\\nValue counts for {column}:\")\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found errant data in mileage field. Adding to \"to_do\" to address with data owner/stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Mileage(kmpl)\"] == \"bs iv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing df col names to be more apporpriate for db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dataframe columns to match with the table column names\n",
    "df = df.rename(columns={\n",
    "    'Car_Name': 'name',\n",
    "    'Make': 'make',\n",
    "    'Model': 'model',\n",
    "    'Make_Year': 'year',\n",
    "    'Color': 'color',\n",
    "    'Body_Type': 'body_style',\n",
    "    'Mileage_Run': 'mileage',\n",
    "    'No_of_Owners': 'num_owners',\n",
    "    'Seating_Capacity': 'seating_capacity',\n",
    "    'Fuel_Type': 'fuel_type',\n",
    "    'Fuel_Tank_Capacity(L)': 'fuel_capacity',\n",
    "    'Engine_Type': 'engine_type',\n",
    "    'CC_Displacement': 'cc_displacement',\n",
    "    'Transmission': 'transmission_gears',\n",
    "    'Transmission_Type': 'transmission_type',\n",
    "    'Power(BHP)': 'bhp',\n",
    "    'Torque(Nm)': 'torque',\n",
    "    'Mileage(kmpl)': 'fuel_economy',\n",
    "    'Emission': 'emission_class',\n",
    "    'Price': 'price',\n",
    "    'engine_litres': 'engine_litres',\n",
    "    'drive_train': 'drive_train'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking max len of each column in the df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_dict = {df.columns[i]: df.iloc[:, i].astype(str).map(len).max() for i in range(df.shape[1])}\n",
    "\n",
    "print(max_len_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to postgres db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@localhost/car_db\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        DROP TABLE IF EXISTS cars;\n",
    "        CREATE TABLE cars (\n",
    "            name VARCHAR(64),\n",
    "            make VARCHAR(64),\n",
    "            model VARCHAR(64),\n",
    "            year SMALLINT,\n",
    "            color VARCHAR(12),\n",
    "            body_style VARCHAR(24),\n",
    "            mileage INTEGER,\n",
    "            num_owners SMALLINT,\n",
    "            seating_capacity SMALLINT,\n",
    "            fuel_type VARCHAR(24),\n",
    "            fuel_capacity SMALLINT,\n",
    "            engine_type VARCHAR(255),\n",
    "            cc_displacement SMALLINT,\n",
    "            transmission_gears VARCHAR(3),\n",
    "            transmission_type VARCHAR(10),\n",
    "            bhp REAL,\n",
    "            torque REAL,\n",
    "            fuel_economy VARCHAR(24),\n",
    "            emission_class VARCHAR(10),\n",
    "            price INTEGER,\n",
    "            engine_litres REAL,\n",
    "            drive_train VARCHAR(3)\n",
    "        );\n",
    "    \"\"\"))\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the above cell, fuel_economy should be a real, but there are two entries that contain strings and have yet to be fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from df into postgresdb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create sqlalchemy engine\n",
    "engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@localhost/car_db\")\n",
    "\n",
    "df.to_sql('cars', engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see if loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result_set = conn.execute(text(\"SELECT * FROM cars LIMIT 10\"))\n",
    "    for row in result_set:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert serial int primary key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"ALTER TABLE cars ADD COLUMN id SERIAL PRIMARY KEY;\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    result_set = conn.execute(text(\"SELECT * FROM cars LIMIT 10\"))\n",
    "    for row in result_set:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a read-only user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@localhost/car_db\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE USER car_reader WITH PASSWORD 'read_only';\n",
    "        GRANT CONNECT ON DATABASE car_db TO car_reader;\n",
    "        GRANT USAGE ON SCHEMA public TO car_reader;\n",
    "        GRANT SELECT ON ALL TABLES IN SCHEMA public TO car_reader;\n",
    "        ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO car_reader;\n",
    "        \"\"\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pg_database_owner', False, True, False, False, False, False, -1, '********', None, False, None, 6171)\n",
      "('pg_read_all_data', False, True, False, False, False, False, -1, '********', None, False, None, 6181)\n",
      "('pg_write_all_data', False, True, False, False, False, False, -1, '********', None, False, None, 6182)\n",
      "('pg_monitor', False, True, False, False, False, False, -1, '********', None, False, None, 3373)\n",
      "('pg_read_all_settings', False, True, False, False, False, False, -1, '********', None, False, None, 3374)\n",
      "('pg_read_all_stats', False, True, False, False, False, False, -1, '********', None, False, None, 3375)\n",
      "('pg_stat_scan_tables', False, True, False, False, False, False, -1, '********', None, False, None, 3377)\n",
      "('pg_read_server_files', False, True, False, False, False, False, -1, '********', None, False, None, 4569)\n",
      "('pg_write_server_files', False, True, False, False, False, False, -1, '********', None, False, None, 4570)\n",
      "('pg_execute_server_program', False, True, False, False, False, False, -1, '********', None, False, None, 4571)\n",
      "('pg_signal_backend', False, True, False, False, False, False, -1, '********', None, False, None, 4200)\n",
      "('pg_checkpoint', False, True, False, False, False, False, -1, '********', None, False, None, 4544)\n",
      "('postgres', True, True, True, True, True, True, -1, '********', None, True, None, 10)\n",
      "('car_reader', False, True, False, False, True, False, -1, '********', None, False, None, 17330)\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    result_set = conn.execute(text(\"SELECT * FROM pg_roles\"))\n",
    "    for row in result_set:\n",
    "        print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
